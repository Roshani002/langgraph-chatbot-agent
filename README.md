# Chatbot Agent with Memory & Human-in-the-Loop

A simple chatbot agent built with Langgraph and LangChain.

## Features
- **Persistent memory** via `MemorySaver`
- **Human-in-the-loop** clarification using `interrupt` + `ask_user_for_clarification` tool
- **External search** integration (TavilySearch)
- Runs locally in VSCode **and** in LangGraph Studio UI

---

## ğŸ“ Project Structure

```
Chatbot_Agent/
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ .env                 # Your API keys 
â”œâ”€â”€ langgraph.json       # Langgraph config which specifies the dependencies, graphs, environment variables
â”œâ”€â”€ venv/                # Python virtual environment
â”œâ”€â”€ .langgraph_api/      # LangGraph Studio cache (auto-created by langgraph dev command)
â””â”€â”€ agent/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ agent.py         # Graph definition & runtime
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ nodes.py     # ToolNode wiring
        â”œâ”€â”€ state.py     # State schema
        â””â”€â”€ tools.py     # tools
```

---

## ğŸ› ï¸ Prerequisites

- Python 3.10+
- langchain
- langchain-tavily
- langchain-core
- langchain-community
- langchain-google-genai
- langgraph
- langgraph-cli[inmem]
- ipython
- python-dotenv

---

## ğŸ” How It Works

- **Memory**  
  Uses `MemorySaver` to persist conversation history across sessions.

- **Human-in-the-Loop**  
  If the AI needs more detail, it triggers an `interrupt` and calls `ask_user_for_clarification`, pausing until you reply.

- **Tools**  
  - **TavilySearch**: external web/search queries  
  - **ask_user_for_clarification**: targeted follow-up questions  

---

## ğŸš€ How to Run Locally

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/chatbot-agent.git
cd chatbot-agent
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On Mac/Linux
source venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies
Since this project uses **LangGraph** with dependencies defined in `langgraph.json`, you do not need a `requirements.txt` file.
- install dependencies as listed inside `langgraph.json`.

### 4ï¸âƒ£ Set up environment variables
Create a `.env` file in the root folder and add your API keys:
```bash
GOOGLE_API_KEY=your_google_api_key
TAVILY_API_KEY=your_tavily_api_key
LANGSMITH_API_KEY=your_langsmith_api_key
```

### 5ï¸âƒ£ Prepare the code for local run
- **Uncomment** the `while True` interactive loop in `agent.py`.
- **Uncomment** the import of `dotenv` and `load_dotenv()` in both `agent.py` and `tools.py`.

### 6ï¸âƒ£ Run the chatbot agent
```bash
python agent/agent.py
```

This will start the chatbot in an interactive terminal session.

---

## ğŸŒ Running in LangGraph Studio
- Follow steps: https://langchain-ai.lang.chat/langgraph/tutorials/langgraph-platform/local-server/
- (for run in langgraph studio docker is required)
---



